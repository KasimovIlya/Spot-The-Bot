# Spot-The-Bot

В данном репозитории сейчас находятся две модели (BERT и ELMo) для получения n-грамм эмбеддингов по очищенному корпусу русских текстов. Сам корпус на GitHub не влезает, поэтому прикладываю тестовую часть (шапку из первых десяти текстов). Для работы с ELMo нужно будет в папку model распковать архив по ссылке: http://vectors.nlpl.eu/repository/11/170.zip. Скрипты main.py предполагают наличие обученных автоэнкодеров в папках auto_encoder. Автоэнкодер обучается на данных, находящихся в папке auto_encoder\train. Данные - эмбеддинги, полученные со всего очищенного корпуса и сохранённые в матрицу/-ы, их можно извлечь с помощью скриптов get_embeddings.py. Поэтому для корректной работы с каждой моделью очерёдность действиий следующая:

1) Запустить скрипт get_embeddings.py
2) Создать в папку train в директории auto_encoder.
3) Переместить полученные на п.1 данные в train.
4) Запустить скрипт learn_model.py
5) Запустить скрипт main.py (нужно будет изменить выходной путь .csv файлов на свой)

Все комментарии к методам есть в коде.
